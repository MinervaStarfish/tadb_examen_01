# âœ¨ Proyecto de Base de Datos en AWS con PostgreSQL y DBeaver âœ¨

---
## ğŸ“„ InformaciÃ³n del Proyecto

**ğŸ‘¨â€ğŸ“ Estudiante:** Mariana Osorio Rojas  
**ğŸŒŸ ID:** 464679  
**ğŸ“§ Correo:** mariana.osorioro@upb.edu.co  
**ğŸ« Universidad:** Pontificia Bolivariana  
**ğŸ“š Facultad:** IngenierÃ­as - IngenierÃ­a de Sistemas e InformÃ¡tica  
**ğŸ“ˆ Materia:** TÃ³picos Avanzados en Bases de Datos  

---
## ğŸ“š IntroducciÃ³n

Este proyecto tiene como objetivo la implementaciÃ³n de una base de datos en la nube utilizando **Amazon Web Services (AWS)** con **PostgreSQL**. Se establecerÃ¡ una conexiÃ³n remota mediante **DBeaver**, permitiendo diseÃ±ar e implementar un modelo de datos para ejecutar consultas avanzadas, funciones y procedimientos almacenados para el anÃ¡lisis eficiente de la informaciÃ³n.

---
## ğŸ› ï¸ TecnologÃ­as Utilizadas

- ğŸ¢ **Arquitectura en la nube:** AWS (Amazon Web Services)
- ğŸ“ **Motor de base de datos:** PostgreSQL
- ğŸ’» **IDE utilizado:** DBeaver

---
## ğŸ“ Estructura del Proyecto

El proyecto estÃ¡ organizado en las siguientes carpetas y archivos:

- **1_docs/** ğŸ“š - DocumentaciÃ³n relevante, incluyendo el enunciado del proyecto y manuales.
- **2_diagrama/** ğŸ¨ - Diagramas relacionales y representaciones visuales del modelo de datos.
- **3_scripts/** âš™ï¸ - Scripts SQL para la implementaciÃ³n del esquema y consultas.
- **4_datos/** ğŸ“‚ - Archivos CSV con datos de empleados, cargos, departamentos, etc.
- **5_archivos_salida/** ğŸ“„ - Archivos generados con los resultados de consultas y funciones.
- **README.md** - DocumentaciÃ³n general del proyecto.
- **.gitignore** - Archivo para excluir archivos innecesarios del control de versiones.

---
## ğŸŒŸ Fases de EjecuciÃ³n

### ğŸ› ï¸ Etapa 1: Abastecimiento
Se despliega una instancia de **PostgreSQL en AWS RDS**, configurando los parÃ¡metros de seguridad y accesibilidad necesarios.

### ğŸ”‘ Etapa 2: ConfiguraciÃ³n de Conexiones Remotas
Se establece la conexiÃ³n remota desde **DBeaver** utilizando credenciales de AWS, asegurando la autenticaciÃ³n y el cifrado adecuado.

### ğŸ“š Etapa 3: DiseÃ±o e ImplementaciÃ³n del Modelo de Datos
Se crean las **tablas y relaciones** del modelo de datos, asegurando la integridad y optimizaciÃ³n del esquema.

### ğŸ”– Etapa 4: ImplementaciÃ³n de Consultas SQL
Se desarrollan consultas utilizando **CTE y funciones ventana** para analizar los datos y realizar cÃ¡lculos.

### âš™ï¸ Etapa 5: Funciones y Procedimientos
Se implementan **funciones y procedimientos almacenados** para automatizar el cÃ¡lculo de costos y nÃ³minas.

---
## ğŸ› ï¸ Instrucciones de InstalaciÃ³n y Uso

1. **Descargar el Repositorio**  
   ```bash
   git clone <URL_DEL_REPOSITORIO>
   cd <NOMBRE_DEL_PROYECTO>
   ```

2. **Instalar PostgreSQL y DBeaver**  
   - Descargar e instalar **PostgreSQL** desde su [sitio oficial](https://www.postgresql.org/download/).
   - Descargar e instalar **DBeaver** desde su [sitio oficial](https://dbeaver.io/download/).

3. **Configurar la Base de Datos en AWS**  
   - Crear una **instancia RDS** con PostgreSQL en AWS.
   - Configurar reglas de seguridad para acceso remoto.

4. **Conectar DBeaver a la Base de Datos**  
   - Agregar una **nueva conexiÃ³n PostgreSQL** en DBeaver.
   - Ingresar las **credenciales de AWS**.
   - Verificar la conexiÃ³n.

5. **Ejecutar los Scripts**  
   - Importar y ejecutar los **scripts SQL** desde la carpeta `3_scripts/`.
   - Analizar los datos y verificar los resultados en `5_archivos_salida/`.

---
## ğŸ’¼ ColaboraciÃ³n

Si deseas contribuir a este proyecto:

1. **Forkea** el repositorio y clona una copia local.
2. Crea una **rama** para tu contribuciÃ³n (`git checkout -b mi-nueva-funcionalidad`).
3. Realiza tus cambios y confÃ­rmalos (`git commit -m "Agregado nueva funcionalidad"`).
4. Sube tus cambios (`git push origin mi-nueva-funcionalidad`).
5. Crea un **Pull Request** para su revisiÃ³n.

---
## ğŸ“š ConclusiÃ³n

Este proyecto demuestra la implementaciÃ³n de una **base de datos en la nube** utilizando **PostgreSQL en AWS**, con conexiÃ³n remota a travÃ©s de **DBeaver**. Se desarrollaron consultas avanzadas y funciones para el anÃ¡lisis eficiente de datos en un entorno seguro y escalable.

---
